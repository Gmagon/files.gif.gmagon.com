# -*- coding: utf-8 -*-

from scrapy import cmdline

# 先执行爬虫
cmdline.execute("scrapy crawl dwowan_gif_spider".split())

# 然后使用git上传到远程文件服务器


# 然后通过审核本地的mongodb中的数据来，分类，打标签，提交到远程数据库中。
# 方法: (1)图像检测AI分析; (2)图像原先内容描述处理



# 自动调度执行，循环操作
